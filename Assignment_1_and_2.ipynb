{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kingketan9/ApplicationsOfAI-Labs/blob/main/Assignment_1_and_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**"
      ],
      "metadata": {
        "id": "fJByBYQCyH7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) **Beautiful Soup** is a widely used Python-based library used for data collection. It operates using a ‘branch-like’ structure that is useful when looking to parse target data in either XML or HTML format. \n",
        "\n",
        "# **Task 1 : Explore the same**"
      ],
      "metadata": {
        "id": "3n2zRDp6yMCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2: Go through NLTK exercise.ipynb and text representation.ipynb**\n",
        "\n"
      ],
      "metadata": {
        "id": "OiGUEQmHye5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 3: Process the following transcript: https://www.forbes.com/sites/robtoews/2023/02/07/the-next-generation-of-large-language-models/?fbclid=IwAR3HM165sf71CJS_RSztDi2D4hQSHvUi93zoGsEW87PqOwhcHTGw3FwsciQ&sh=61e0668b18db through Beautiful Soup**"
      ],
      "metadata": {
        "id": "CrDm1D60zNqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.forbes.com/sites/robtoews/2023/02/07/the-next-generation-of-large-language-models/?fbclid=IwAR3HM165sf71CJS_RSztDi2D4hQSHvUi93zoGsEW87PqOwhcHTGw3FwsciQ&sh=61e0668b18db'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "title = soup.find('h1', {'class': 'fs-headline'}).text\n",
        "\n",
        "print('Title :- ', title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPrMCt0G8EUR",
        "outputId": "613fc516-1675-46c7-94ff-1f0cd0ff36bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title :-  The Next Generation Of Large Language Models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data cleaning** is a time consuming and unenjoyable task, yet it's a very important one. Keep in mind, \"garbage in, garbage out\".\n",
        "Feeding dirty data into a model will give us results that are meaningless.\n",
        "Objective:\n",
        "\n",
        "    Getting the data\n",
        "    Cleaning the data\n",
        "    Organizing the data - organize the cleaned data into a way that is easy to input into other algorithms\n",
        "\n",
        "Output :\n",
        "cleaned and organized data in two standard text formats:\n",
        "\n",
        "    Corpus - a collection of text\n",
        "    Document-Term Matrix - word counts in matrix format\n",
        "\n"
      ],
      "metadata": {
        "id": "kD02HPh81Mhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 4**: Perform the following data cleaning on transcript: \n",
        "*  Make text all lower case \n",
        "*   Remove punctuation \n",
        "* Remove numerical values \n",
        "* Remove common non-sensical text (/n) \n",
        "* Tokenize text \n",
        "* Remove stop words\n"
      ],
      "metadata": {
        "id": "CWhw12M31iuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample transcript\n",
        "transcript = \"\"\"In case you haven’t heard, artificial intelligence is the hot new thing.\n",
        "\n",
        "Generative AI seems to be on the lips of every venture capitalist, entrepreneur, Fortune 500 CEO and journalist these days, from Silicon Valley to Davos.\n",
        "\n",
        "To those who started paying real attention to AI in 2022, it may seem that technologies like ChatGPT and Stable Diffusion came out of nowhere to take the world by storm. They didn’t.\n",
        "\n",
        "Back in 2020, we wrote an article in this column predicting that generative AI would be one of the pillars of the next generation of artificial intelligence\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WEdAtHB8g_y",
        "outputId": "ca02c5fb-19fd-4bee-ae3f-303f38bdb3ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make text all lower case\n",
        "transcript = transcript.lower()\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfe6fB0p8ttQ",
        "outputId": "60ce19a8-7b54-40e1-c07d-f79fabfeba7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in case you haven’t heard, artificial intelligence is the hot new thing.\n",
            "\n",
            "generative ai seems to be on the lips of every venture capitalist, entrepreneur, fortune 500 ceo and journalist these days, from silicon valley to davos.\n",
            "\n",
            "to those who started paying real attention to ai in 2022, it may seem that technologies like chatgpt and stable diffusion came out of nowhere to take the world by storm. they didn’t.\n",
            "\n",
            "back in 2020, we wrote an article in this column predicting that generative ai would be one of the pillars of the next generation of artificial intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation\n",
        "transcript = transcript.translate(str.maketrans(\"\", \"\", string.punctuation)) \n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrxy-8b58wG-",
        "outputId": "cc87499f-b5c9-4feb-8bb5-79d89dd137f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in case you haven’t heard artificial intelligence is the hot new thing\n",
            "\n",
            "generative ai seems to be on the lips of every venture capitalist entrepreneur fortune 500 ceo and journalist these days from silicon valley to davos\n",
            "\n",
            "to those who started paying real attention to ai in 2022 it may seem that technologies like chatgpt and stable diffusion came out of nowhere to take the world by storm they didn’t\n",
            "\n",
            "back in 2020 we wrote an article in this column predicting that generative ai would be one of the pillars of the next generation of artificial intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove numerical values\n",
        "transcript = re.sub(r'\\d+', '', transcript)\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yNif8Dl8ydk",
        "outputId": "1e2530f9-acd0-41d8-a2de-a0e38dafe48c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in case you haven’t heard artificial intelligence is the hot new thing\n",
            "\n",
            "generative ai seems to be on the lips of every venture capitalist entrepreneur fortune  ceo and journalist these days from silicon valley to davos\n",
            "\n",
            "to those who started paying real attention to ai in  it may seem that technologies like chatgpt and stable diffusion came out of nowhere to take the world by storm they didn’t\n",
            "\n",
            "back in  we wrote an article in this column predicting that generative ai would be one of the pillars of the next generation of artificial intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove common non-sensical text (/n)\n",
        "transcript = transcript.replace('\\n', ' ')\n",
        "\n",
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYBxfzJj80cq",
        "outputId": "7a7717fd-9f88-4208-e62a-a982951cb720"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in case you haven’t heard artificial intelligence is the hot new thing  generative ai seems to be on the lips of every venture capitalist entrepreneur fortune  ceo and journalist these days from silicon valley to davos  to those who started paying real attention to ai in  it may seem that technologies like chatgpt and stable diffusion came out of nowhere to take the world by storm they didn’t  back in  we wrote an article in this column predicting that generative ai would be one of the pillars of the next generation of artificial intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text\n",
        "tokens = word_tokenize(transcript)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXRJWdpM82lb",
        "outputId": "145d0042-16ce-4fa2-c46b-6eff3c2f541d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in', 'case', 'you', 'haven', '’', 't', 'heard', 'artificial', 'intelligence', 'is', 'the', 'hot', 'new', 'thing', 'generative', 'ai', 'seems', 'to', 'be', 'on', 'the', 'lips', 'of', 'every', 'venture', 'capitalist', 'entrepreneur', 'fortune', 'ceo', 'and', 'journalist', 'these', 'days', 'from', 'silicon', 'valley', 'to', 'davos', 'to', 'those', 'who', 'started', 'paying', 'real', 'attention', 'to', 'ai', 'in', 'it', 'may', 'seem', 'that', 'technologies', 'like', 'chatgpt', 'and', 'stable', 'diffusion', 'came', 'out', 'of', 'nowhere', 'to', 'take', 'the', 'world', 'by', 'storm', 'they', 'didn', '’', 't', 'back', 'in', 'we', 'wrote', 'an', 'article', 'in', 'this', 'column', 'predicting', 'that', 'generative', 'ai', 'would', 'be', 'one', 'of', 'the', 'pillars', 'of', 'the', 'next', 'generation', 'of', 'artificial', 'intelligence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqO5EcM284Qo",
        "outputId": "04e4d37d-eee7-4b08-eabe-5ff20f1f65af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['case', '’', 'heard', 'artificial', 'intelligence', 'hot', 'new', 'thing', 'generative', 'ai', 'seems', 'lips', 'every', 'venture', 'capitalist', 'entrepreneur', 'fortune', 'ceo', 'journalist', 'days', 'silicon', 'valley', 'davos', 'started', 'paying', 'real', 'attention', 'ai', 'may', 'seem', 'technologies', 'like', 'chatgpt', 'stable', 'diffusion', 'came', 'nowhere', 'take', 'world', 'storm', '’', 'back', 'wrote', 'article', 'column', 'predicting', 'generative', 'ai', 'would', 'one', 'pillars', 'next', 'generation', 'artificial', 'intelligence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 5: Apply POS tagging, Stemming, Lemmatization, WSD, Chunking for  the outcome of task 4**"
      ],
      "metadata": {
        "id": "tLPV4ViP0g_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.wsd import lesk\n",
        "from nltk import pos_tag, ne_chunk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "# POS tagging\n",
        "pos_tags = pos_tag(filtered_tokens)\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "# WSD\n",
        "wsd_token = 'transformative'\n",
        "wsd_sentence = ' '.join(filtered_tokens)\n",
        "wsd_synset = lesk(wsd_sentence, wsd_token)\n",
        "\n",
        "# Chunking\n",
        "chunked_tokens = ne_chunk(pos_tags)\n",
        "\n",
        "print('Filtered tokens:', filtered_tokens)\n",
        "print('POS tags:', pos_tags)\n",
        "print('Stemmed tokens:', stemmed_tokens)\n",
        "print('Lemmatized tokens:', lemmatized_tokens)\n",
        "print('WSD token:', wsd_token)\n",
        "print('Chunked tokens:', chunked_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XFPgz0491Xe",
        "outputId": "f6b565aa-d26f-4758-b192-c9b36826fd17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered tokens: ['case', '’', 'heard', 'artificial', 'intelligence', 'hot', 'new', 'thing', 'generative', 'ai', 'seems', 'lips', 'every', 'venture', 'capitalist', 'entrepreneur', 'fortune', 'ceo', 'journalist', 'days', 'silicon', 'valley', 'davos', 'started', 'paying', 'real', 'attention', 'ai', 'may', 'seem', 'technologies', 'like', 'chatgpt', 'stable', 'diffusion', 'came', 'nowhere', 'take', 'world', 'storm', '’', 'back', 'wrote', 'article', 'column', 'predicting', 'generative', 'ai', 'would', 'one', 'pillars', 'next', 'generation', 'artificial', 'intelligence']\n",
            "POS tags: [('case', 'NN'), ('’', 'NNP'), ('heard', 'VBD'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('hot', 'JJ'), ('new', 'JJ'), ('thing', 'NN'), ('generative', 'JJ'), ('ai', 'NN'), ('seems', 'VBZ'), ('lips', 'JJ'), ('every', 'DT'), ('venture', 'NN'), ('capitalist', 'JJ'), ('entrepreneur', 'NN'), ('fortune', 'NN'), ('ceo', 'JJ'), ('journalist', 'NN'), ('days', 'NNS'), ('silicon', 'VBP'), ('valley', 'JJ'), ('davos', 'NN'), ('started', 'VBD'), ('paying', 'VBG'), ('real', 'JJ'), ('attention', 'NN'), ('ai', 'NN'), ('may', 'MD'), ('seem', 'VB'), ('technologies', 'NNS'), ('like', 'IN'), ('chatgpt', 'NN'), ('stable', 'JJ'), ('diffusion', 'NN'), ('came', 'VBD'), ('nowhere', 'RB'), ('take', 'JJ'), ('world', 'NN'), ('storm', 'NN'), ('’', 'NNP'), ('back', 'RB'), ('wrote', 'VBD'), ('article', 'NN'), ('column', 'NN'), ('predicting', 'VBG'), ('generative', 'JJ'), ('ai', 'NN'), ('would', 'MD'), ('one', 'CD'), ('pillars', 'NNS'), ('next', 'IN'), ('generation', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN')]\n",
            "Stemmed tokens: ['case', '’', 'heard', 'artifici', 'intellig', 'hot', 'new', 'thing', 'gener', 'ai', 'seem', 'lip', 'everi', 'ventur', 'capitalist', 'entrepreneur', 'fortun', 'ceo', 'journalist', 'day', 'silicon', 'valley', 'davo', 'start', 'pay', 'real', 'attent', 'ai', 'may', 'seem', 'technolog', 'like', 'chatgpt', 'stabl', 'diffus', 'came', 'nowher', 'take', 'world', 'storm', '’', 'back', 'wrote', 'articl', 'column', 'predict', 'gener', 'ai', 'would', 'one', 'pillar', 'next', 'gener', 'artifici', 'intellig']\n",
            "Lemmatized tokens: ['case', '’', 'heard', 'artificial', 'intelligence', 'hot', 'new', 'thing', 'generative', 'ai', 'seems', 'lip', 'every', 'venture', 'capitalist', 'entrepreneur', 'fortune', 'ceo', 'journalist', 'day', 'silicon', 'valley', 'davos', 'started', 'paying', 'real', 'attention', 'ai', 'may', 'seem', 'technology', 'like', 'chatgpt', 'stable', 'diffusion', 'came', 'nowhere', 'take', 'world', 'storm', '’', 'back', 'wrote', 'article', 'column', 'predicting', 'generative', 'ai', 'would', 'one', 'pillar', 'next', 'generation', 'artificial', 'intelligence']\n",
            "WSD token: transformative\n",
            "Chunked tokens: (S\n",
            "  case/NN\n",
            "  ’/NNP\n",
            "  heard/VBD\n",
            "  artificial/JJ\n",
            "  intelligence/NN\n",
            "  hot/JJ\n",
            "  new/JJ\n",
            "  thing/NN\n",
            "  generative/JJ\n",
            "  ai/NN\n",
            "  seems/VBZ\n",
            "  lips/JJ\n",
            "  every/DT\n",
            "  venture/NN\n",
            "  capitalist/JJ\n",
            "  entrepreneur/NN\n",
            "  fortune/NN\n",
            "  ceo/JJ\n",
            "  journalist/NN\n",
            "  days/NNS\n",
            "  silicon/VBP\n",
            "  valley/JJ\n",
            "  davos/NN\n",
            "  started/VBD\n",
            "  paying/VBG\n",
            "  real/JJ\n",
            "  attention/NN\n",
            "  ai/NN\n",
            "  may/MD\n",
            "  seem/VB\n",
            "  technologies/NNS\n",
            "  like/IN\n",
            "  chatgpt/NN\n",
            "  stable/JJ\n",
            "  diffusion/NN\n",
            "  came/VBD\n",
            "  nowhere/RB\n",
            "  take/JJ\n",
            "  world/NN\n",
            "  storm/NN\n",
            "  ’/NNP\n",
            "  back/RB\n",
            "  wrote/VBD\n",
            "  article/NN\n",
            "  column/NN\n",
            "  predicting/VBG\n",
            "  generative/JJ\n",
            "  ai/NN\n",
            "  would/MD\n",
            "  one/CD\n",
            "  pillars/NNS\n",
            "  next/IN\n",
            "  generation/NN\n",
            "  artificial/JJ\n",
            "  intelligence/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 6**: Perform following feature extraction task for the outcome of task 4:\n",
        "\n",
        "*   Bag of words \n",
        "*   N gram\n",
        "*   tf-idf\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VFmKWTPM20Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Bag of words\n",
        "bow_vectorizer = CountVectorizer()\n",
        "bow = bow_vectorizer.fit_transform(filtered_tokens)\n",
        "bow_feature_names = bow_vectorizer.get_feature_names()\n",
        "\n",
        "\n",
        "\n",
        "# tf-idf\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf = tfidf_vectorizer.fit_transform(filtered_tokens)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "\n",
        "print('Filtered tokens:', filtered_tokens)\n",
        "print('Bag of words:', bow.toarray())\n",
        "print('Bag of words feature names:', bow_feature_names)\n",
        "print('tf-idf:', tfidf.toarray())\n",
        "print('tf-idf feature names:', tfidf_feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjAjtp3G_vlu",
        "outputId": "5baee003-bb55-4684-8111-ef00665c8a63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered tokens: ['case', '’', 'heard', 'artificial', 'intelligence', 'hot', 'new', 'thing', 'generative', 'ai', 'seems', 'lips', 'every', 'venture', 'capitalist', 'entrepreneur', 'fortune', 'ceo', 'journalist', 'days', 'silicon', 'valley', 'davos', 'started', 'paying', 'real', 'attention', 'ai', 'may', 'seem', 'technologies', 'like', 'chatgpt', 'stable', 'diffusion', 'came', 'nowhere', 'take', 'world', 'storm', '’', 'back', 'wrote', 'article', 'column', 'predicting', 'generative', 'ai', 'would', 'one', 'pillars', 'next', 'generation', 'artificial', 'intelligence']\n",
            "Bag of words: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Bag of words feature names: ['ai', 'article', 'artificial', 'attention', 'back', 'came', 'capitalist', 'case', 'ceo', 'chatgpt', 'column', 'davos', 'days', 'diffusion', 'entrepreneur', 'every', 'fortune', 'generation', 'generative', 'heard', 'hot', 'intelligence', 'journalist', 'like', 'lips', 'may', 'new', 'next', 'nowhere', 'one', 'paying', 'pillars', 'predicting', 'real', 'seem', 'seems', 'silicon', 'stable', 'started', 'storm', 'take', 'technologies', 'thing', 'valley', 'venture', 'world', 'would', 'wrote']\n",
            "tf-idf: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "tf-idf feature names: ['ai', 'article', 'artificial', 'attention', 'back', 'came', 'capitalist', 'case', 'ceo', 'chatgpt', 'column', 'davos', 'days', 'diffusion', 'entrepreneur', 'every', 'fortune', 'generation', 'generative', 'heard', 'hot', 'intelligence', 'journalist', 'like', 'lips', 'may', 'new', 'next', 'nowhere', 'one', 'paying', 'pillars', 'predicting', 'real', 'seem', 'seems', 'silicon', 'stable', 'started', 'storm', 'take', 'technologies', 'thing', 'valley', 'venture', 'world', 'would', 'wrote']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# N - grams\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\"\"\"In case you haven’t heard, artificial intelligence is the hot new thing.\n",
        "\n",
        "Generative AI seems to be on the lips of every venture capitalist, entrepreneur, Fortune 500 CEO and journalist these days, from Silicon Valley to Davos.\n",
        "\n",
        "To those who started paying real attention to AI in 2022, it may seem that technologies like ChatGPT and Stable Diffusion came out of nowhere to take the world by storm. They didn’t.\n",
        "\n",
        "Back in 2020, we wrote an article in this column predicting that generative AI would be one of the pillars of the next generation of artificial intelligence\"\"\"]\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "\n",
        "print(X.toarray())\n",
        "print(feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vkgm9KtBw8X",
        "outputId": "4c00e3a1-7997-400f-815c-73048d3defb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1\n",
            "  2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1\n",
            "  1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1\n",
            "  1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1]]\n",
            "['2020', '2020 we', '2020 we wrote', '2022', '2022 it', '2022 it may', '500', '500 ceo', '500 ceo and', 'ai', 'ai in', 'ai in 2022', 'ai seems', 'ai seems to', 'ai would', 'ai would be', 'an', 'an article', 'an article in', 'and', 'and journalist', 'and journalist these', 'and stable', 'and stable diffusion', 'article', 'article in', 'article in this', 'artificial', 'artificial intelligence', 'artificial intelligence is', 'attention', 'attention to', 'attention to ai', 'back', 'back in', 'back in 2020', 'be', 'be on', 'be on the', 'be one', 'be one of', 'by', 'by storm', 'by storm they', 'came', 'came out', 'came out of', 'capitalist', 'capitalist entrepreneur', 'capitalist entrepreneur fortune', 'case', 'case you', 'case you haven', 'ceo', 'ceo and', 'ceo and journalist', 'chatgpt', 'chatgpt and', 'chatgpt and stable', 'column', 'column predicting', 'column predicting that', 'davos', 'davos to', 'davos to those', 'days', 'days from', 'days from silicon', 'didn', 'didn back', 'didn back in', 'diffusion', 'diffusion came', 'diffusion came out', 'entrepreneur', 'entrepreneur fortune', 'entrepreneur fortune 500', 'every', 'every venture', 'every venture capitalist', 'fortune', 'fortune 500', 'fortune 500 ceo', 'from', 'from silicon', 'from silicon valley', 'generation', 'generation of', 'generation of artificial', 'generative', 'generative ai', 'generative ai seems', 'generative ai would', 'haven', 'haven heard', 'haven heard artificial', 'heard', 'heard artificial', 'heard artificial intelligence', 'hot', 'hot new', 'hot new thing', 'in', 'in 2020', 'in 2020 we', 'in 2022', 'in 2022 it', 'in case', 'in case you', 'in this', 'in this column', 'intelligence', 'intelligence is', 'intelligence is the', 'is', 'is the', 'is the hot', 'it', 'it may', 'it may seem', 'journalist', 'journalist these', 'journalist these days', 'like', 'like chatgpt', 'like chatgpt and', 'lips', 'lips of', 'lips of every', 'may', 'may seem', 'may seem that', 'new', 'new thing', 'new thing generative', 'next', 'next generation', 'next generation of', 'nowhere', 'nowhere to', 'nowhere to take', 'of', 'of artificial', 'of artificial intelligence', 'of every', 'of every venture', 'of nowhere', 'of nowhere to', 'of the', 'of the next', 'of the pillars', 'on', 'on the', 'on the lips', 'one', 'one of', 'one of the', 'out', 'out of', 'out of nowhere', 'paying', 'paying real', 'paying real attention', 'pillars', 'pillars of', 'pillars of the', 'predicting', 'predicting that', 'predicting that generative', 'real', 'real attention', 'real attention to', 'seem', 'seem that', 'seem that technologies', 'seems', 'seems to', 'seems to be', 'silicon', 'silicon valley', 'silicon valley to', 'stable', 'stable diffusion', 'stable diffusion came', 'started', 'started paying', 'started paying real', 'storm', 'storm they', 'storm they didn', 'take', 'take the', 'take the world', 'technologies', 'technologies like', 'technologies like chatgpt', 'that', 'that generative', 'that generative ai', 'that technologies', 'that technologies like', 'the', 'the hot', 'the hot new', 'the lips', 'the lips of', 'the next', 'the next generation', 'the pillars', 'the pillars of', 'the world', 'the world by', 'these', 'these days', 'these days from', 'they', 'they didn', 'they didn back', 'thing', 'thing generative', 'thing generative ai', 'this', 'this column', 'this column predicting', 'those', 'those who', 'those who started', 'to', 'to ai', 'to ai in', 'to be', 'to be on', 'to davos', 'to davos to', 'to take', 'to take the', 'to those', 'to those who', 'valley', 'valley to', 'valley to davos', 'venture', 'venture capitalist', 'venture capitalist entrepreneur', 'we', 'we wrote', 'we wrote an', 'who', 'who started', 'who started paying', 'world', 'world by', 'world by storm', 'would', 'would be', 'would be one', 'wrote', 'wrote an', 'wrote an article', 'you', 'you haven', 'you haven heard']\n"
          ]
        }
      ]
    }
  ]
}